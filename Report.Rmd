
---
title: "Non-invasive Prediction Models for Malignant Breast Tumor"
author: "Olivia Fan, Alicia Gong"
date: "`r format(Sys.time(), '%d %B, %Y')`"
bibliography: references.bib
link-citations: true
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, message=F, warning=F, echo=F}
library(knitr)
library(dplyr)
library(tidyverse)
library(e1071)
library(randomForest)
library(caret)
library(ggplot2)
library(psych)
library(BioStatR)
```

```{r include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

# Introduction

Breast cancer is the most common cancer worldwide and the most common cancer diagnosed in the US (Mayo). Each year in the US, about 264,000 cases of breast cancer are diagnosed in women and about 2,400 in men (CDC). 

Early diagnosis of the condition is crucial to improve the survival rate and relieve suffering in patients. Breast carcinoma is one of the most common cancers occurring in the female population world-wide. Mammography is an effective X-ray imaging technology that detects breast cancer early. In clinical oncology, doctors usually perform morphimetric analysis of mammographic images. Nuclear changes occurring during these transformational steps need to be assessed objectively. Variations in nuclear structure are the morphologic hallmark of cancer diagnosis. There is a gradual shift in the nuclear parameters as the disease progresses from benign to malignant.
Nuclear size, shape, chromatin pattern, and nucleoli size and a number have all been reported to change in breast cancer.These nuclear morphometric features have been shown to predict the prognosis of the breast cancer patients.
Classically, benign or malignant breast tumors are diagnosed by radiologists' interpretation of mammograms based on morphometric parameters. However, diagnosing cancer is challenging even for the most skilled doctors. The symptoms are often shared with diseases and conditions that are unrelated to cancer, leading doctors to improperly diagnose the disease. 
According to an expansive study conducted by Dartmouth College, the University of Vermont, and the Fred Hutchinson Cancer Research Center, and published in the March 2015 issue of the Journal of American Medical Association, approximately 13% of the diagnoses missed Stage 1 breast cancer. Meanwhile, 48% failed to detect atypia hyperplasia, a precursor to breast cancer. A significant number also over-diagnosed atypia hyperplasia. 

There is, therefore, an urgent need to find new tools that can identify patients with breast cancer. Our study aims to build supervised machine-learning models to predict the diagnosis of breast cancer and understand the most important variables, to assist doctors and radiologists in accurately interpreting mammography imaging. 

We built 3 models in total: Lasso penalized logistic regression, SVM, and Random Forest. First, we used LASSO penalized logistic regression to select variables and to predict the probabilities. Then, we used the predictors selected by LASSO to build a SVM model. Finally, we build another Random Forest model as a comparison to the SVM model, also for a more straightforward interpretation.

# Data

We obtain the Breast Cancer Wisconsin (Diagnosis) Data Set from Kaggle. The dataset contains diagnosis results and features of the cell nuclei computed from a digitized image of a fine needle aspirate (FNA) of a breast mass for 568 patients. The size of the nucleus is expressed by the features radius and area. The shape is expressed by the features smoothness, concavity, compactness, concave points, symmetry, and fractal dimension. The perimeter expresses both the size and shape of the nucleus. A higher value of shape features corresponds to a less regular contour and, therefore, to a higher probability of malignancy. For each of the features the mean value, worst value (mean of the three largest values),
and standard error are computed for each image, resulting in 30 features of
568 images.

We examined an extensive list of variables in our models, and a full table of them can be found in the appendix.

# Data Processing

The original dataset contains a blank column '...33', so we dropped it. We also dropped the 'id' column, and rename several columns that contains blank space in their names. 

```{r load-data, message = FALSE, echo=F}
cancer<-read_csv("data.csv")%>%
  select(-...33)%>%
  select(-id)%>%
  rename(concave_points_mean='concave points_mean')%>%
  rename(concave_points_worst='concave points_worst')%>%
  rename(concave_points_se='concave points_se'
         )
```


In order to fit SVM on the data, we encode the `diagnosis` variable into a factor variable with level 1 (malignant) and -1 (benign):

```{r, echo=F, warning=F}
cancer_binary<-cancer%>%
  mutate(diagnosis_binary=as.factor(ifelse(diagnosis=="M",1,-1)))
```

We partition the data into training and testing sets using a 70-30 percentage split(70% of the original data as the training set, and 30% as the testing set):

```{r, echo=F, warning=F}
set.seed(123)
dt = sort(sample(nrow(cancer_binary), nrow(cancer_binary)*.7))
cancer_train<-cancer_binary[dt,]
cancer_test<-cancer_binary[-dt,]
```

# Exploratory Data Analysis 

```{r, echo=F, warning=F, fig.height = 2, fig.width = 2, fig.cap = "Distribution of Malignant and Benign Tumors"}
options(repr.plot.width = 10, repr.plot.height = 5)
ggplot(data = cancer, mapping = aes(x = diagnosis)) +
  geom_bar()
```

The bar plot shows that there is a larger number of benign than malignant cancer. 

We divide the data into 3 categories according to their features.
```{r, echo=F, warning=F}
features_mean= cancer[2:11]
features_se= cancer[12:21]
features_worst= cancer[22:31]
```

```{r, echo=F, warning=F, fig.height = 4, fig.width = 4, fig.cap = "Correlation between mean predictors in the dataset"}
library(corrplot)
corrplot(cor(features_mean))
```

Major observations: 

- Radius_mean, perimeter_mean, and area_mean are highly correlated.

- Compactness_mean, concavity_mean and concave_points_mean are highly correlated.


```{r, echo=F, warning=F, fig.height = 10, fig.width = 10, fig.cap = "Scatterplot of mean predictors by malignant (red) and benign (blue) tumors" }
panel.hist <- function(x, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5) )
    h <- hist(x, plot = FALSE)
    breaks <- h$breaks; nB <- length(breaks)
    y <- h$counts; y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, color = "dodgerblue3", ...)
}

pairs(cancer[2:11], 
             method = "pearson", # correlation method
             digits=3,
             pch = '.',
             col=ifelse(cancer$diagnosis=="M", "red", "blue"),
             density = TRUE,  # show density plots
             ellipses = TRUE, # show correlation ellipses
             diag.panel =  panel.hist
             )
```

We observe from the pairwise scatterplot matrix above that the two classifications seem to be generally separable, with distinct regions in the visualization that cleanly cluster without much mingling or mixing. Overall across malignant and benign tumors, there seems to be a strong positive linear relationship between `radius_mean` and `parameter_mean`, `radius_mean` and `area_mean`, as well as `area_mean` and `parameter_mean`, which hints again at the collinearity issue which we will later tackle at through variable selection. While the two classifications together constitute a roughly linear relationship between predictors, malignant tumors (red) generally associate with higher values in both predictors accumulating in the right top corner, while benign tumors (blue) generally associate with lower ones in the left bottom corner.

We observe that there does not seem to be a separating hyperplane for the two classes for predictors in the relationship between `texture_mean` and `symmetry_mean`, and between `smoothness_mean` and  `fractal_dimension_mean` since the observations in two classes mingle together. This hints at the fact that these predictors might not be helpful for the two class classification problem, which we will filter out in our model through variable selection.

The distributions of the predictors seem to be all unimodal, with no apparent outliers and generally right-skewed, with `concavity_mean` and `concave_points_mean` being particularly right-skewed, hinting at the high correlation between the two predictors. Hence we want to consider including only one of them in our model. We take a closer look at the distributions of these two predictors here:

```{r, warning = F, echo=F, fig.height = 2, fig.width = 5, fig.cap = "Distribution of concavity mean and concavity point mean"}
library(cowplot)
p1<-ggplot(cancer, aes(x=concavity_mean)) + labs(title = "Distribution of concavity mean")+
  geom_histogram()
p2<-ggplot(cancer, aes(x=concave_points_mean)) + labs(title = "Distribution of concavity point mean")+
  geom_histogram()
plot_grid(p1, p2, labels = "AUTO")
```

After deriving the histogram comparing distributions of predictors based on the two classifications, we would like to find features with little overlap between benign and malignant classes which will likely to be significant for diagnosis.
We plot the distribution of the predictors separated by the benigh and malignant classes, and observe again that predictors associated with texture, smoothness, symmetry and fractal dimension are inseparable and therefore might not be helpful for the classification problem. For example, the distributions of `smoothness_se`  for benign and malignant cancers almost completely overlap, same do `symmetry_se`, `fractal_dimension_se` and `texture_se`. Therefore, we will consider filter out these predictors in our final model.

```{r, echo=F, warning=F, fig.height = 15, fig.width = 25, fig.cap = "Distribution of predictors by diagnosis"}
source("Functions.R")
# Read data
df = read.csv('data.csv')
# Identify the outcome and features
outcomes = c("diagnosis")
features = names(df)[3:(ncol(df)-1)]
# Keep outcome and features only
df = df[, c(outcomes, features)]
# The outcome is a dichotomous variable. Convert to `factor` to reflect this. Make 'Benign' the first (reference) level.
df$diagnosis = factor(df$diagnosis, levels = c('B', 'M'))
# options(repr.plot.width = 20, repr.plot.height = 15)
plot_data(df, 'diagnosis')
```

# Methodology 

## Model 1: LASSO-Penalized Logistic Regression

We decided to use a LASSO-penalized logistic regression model to perform variable selection by gauging insights into which predictors are the most contributive, since less significant variables are forced to be exactly zero, and the most significant variables are kept in the final model. Also because LASSO is a great tool dealing with multicollinearity issue. Since our EDA shows that many of the input variables are correlated, LASSO will drop the highly correlated features.

As explained in our exploratory data analysis above, we filter out predictors associated with texture, smoothness, fractal dimension and symmetry in our model due to the lack of separation in the values of these predictors for the benign and malignant tumor classes.

### Hyperparameter Tuning

We fitted the LASSO-penalized logistic regression model using the optimal hyperparameter $\lambda= 0.001399$ via cross validation. To explore the interaction between symmetry and the mean for number of concave portions of the contour, we included the interaction term `symmetry_worst*concave_points_mean`.

```{r, warning = F, echo=F}
# Dumy code categorical predictor variables
x <- model.matrix(diagnosis~.-diagnosis_binary-texture_mean-smoothness_mean-symmetry_mean-fractal_dimension_mean-texture_se-smoothness_se-symmetry_se-fractal_dimension_se-texture_worst-smoothness_worst-symmetry_worst-symmetry_worst-fractal_dimension_worst+compactness_mean*concave_points_mean, cancer_train)[,-1]
# Convert the outcome (class) to a numerical variable
y <- ifelse(cancer_train$diagnosis == "M", 1, 0)
```

```{r, echo=F, warning=F, fig.height = 4, fig.width = 4, fig.cap = "LASSO parameter tuning"}
library(glmnet)
# Find the best lambda using cross-validation
set.seed(123)
cv.lasso <- cv.glmnet(x, y, alpha = 1, family = "binomial")
plot(cv.lasso)
```

We derived the following LASSO-penalized logistic regression model coefficients using the optimal hyperparameter $\lambda= 0.001399$: 

```{r, warning = F, echo=F}
cv.lasso$lambda.min
# Final model with lambda.min
lasso.model <- glmnet(x, y, alpha = 1, family = "binomial",
                      lambda = cv.lasso$lambda.min)
df<-as.data.frame(as.matrix(coef(lasso.model)))
df%>%filter(s0!=0)%>%rename("coefficient"=s0)%>%kable(digits=4)
```

### Result: Logistic Model

\begin{align} \log(\frac{P}{1-P}) &= -10.4871-0.1130 \times radius\_mean -33.6480 \times compactness\_mean \\&+14.3918 \times concavity\_mean +19.0997 \times concave\_points\_mean \\ &+ 0.0944 \times area\_se -30.3992 \times compactness\_se -31.2549 \times concavity\_se \\ & +34.8557 \times concave\_points\_se +0.0112 \times radius\_worst +0.0049 \times area\_worst \\ &+4.9213 \times  compactness\_worst +7.6360 \times concavity\_worst + 26.8649 \times concave\_points\_worst \\ &+74.5208 \times compactness\_mean \times concave\_points\_mean \end{align}

### Model Interpretation

We found that while predictors `concavity_mean`, `concave_points_mean`,`area_se`, `radius_worst`, `concave_points_se`, `area_worst`, `compactness_worst`, `concavity_worst`, `concave_points_worst` and `concavity_se` are positively associated with the response log odds, predictors `radius_mean`, `compactness_se` and `compactness_mean` are negatively associated with the response log odds. Of all the predictors, `concave_points_se` and `compactness_mean` have the largest magnitude, and therefore are the most significant predictors. For each 0.01 additional unit increase in `concave_points_se`, the log odds of the probability that a patient is diagnosed as malignant cancer tends to decrease by 34.85% holding all else constant. On the other hand, for each 0.01 additional unit increase in `concavity_se`, the log odds of the probability that a patient is diagnosed as malignant cancer tends to decrease by 31.2549% holding all else constant. By the interaction term, for each 0.01 additional unit increase in `compactness_mean`, the coefficient of `concave_points_mean` is expected to increase by 0.745208, holding all else constant. 

To further interpret the interaction between `compactness_mean` and `concave_points_mean`, we created the following visualization with different levels of fixed `compactness_mean`, at 0.01938 (low), 0.26 (medium) and 0.28670 (high). To avoid interpolation, we first looked at the quantile summaries of these two predictors. There seems to be significant interactions between `compactness_mean` and `concave_points_mean`, since the effect of `concave_points_mean` on the probability changes drastically on the different levels of the `compactness_mean_level` values. For high and medium values of compactness mean level, as the number of concave points increases, the probability that a patient is diagnosed as malignant cancer also tends to increase, and high values of compactness mean level associates with a stronger effect by the number of concave points on this probability. On the other hand, for low values of compactness mean level, the probability tends to stay at nearly 1 and the number of concave points does not affect the probability by a significant amount. Therefore, through this interaction term, we discover that higher levels of compactness mean associates with a stronger effect that concave points mean has on the response probability.

```{r, echo=F, warning=F, out.height  = '80%', out.width = '80%'}
summary(cancer_train$compactness_mean)
summary(cancer_train$concave_points_mean)

df <- data.frame()
cancer_test_low = cancer_test%>%select(-compactness_mean,-concave_points_mean)
duprow=cancer_test_low[1,]
for(i in 1:150)
{
    df = rbind(df,duprow)
}
concave_points_mean = seq(0,0.2,length.out=150)
df$compactness_mean=0.01938
df <- cbind(df,concave_points_mean)
df<- df%>%mutate(logit = -10.4871-0.1130*radius_mean-33.6480*compactness_mean+14.3918*concavity_mean+19.0997*concave_points_mean+0.0944*area_se-30.3992*compactness_se -31.2549*concavity_se +34.8557 *concave_points_se +0.0112*radius_worst+0.0049*area_worst+4.9213*compactness_worst+7.6360*concavity_worst + 26.8649*concave_points_worst+74.5208*compactness_mean*concave_points_mean)
df$compactness_mean_level = "low"

## MEDIUM VALUE OF compactness_mean
df2 <- data.frame()
cancer_test_low = cancer_test%>%select(-compactness_mean,-concave_points_mean)
duprow=cancer_test_low[1,]
for(i in 1:150)
{
    df2 = rbind(df2,duprow)
}
concave_points_mean = seq(0,0.2,length.out=150)
df2$compactness_mean=0.26
df2 <- cbind(df2,concave_points_mean)
df2<- df2%>%mutate(logit = -10.4871-0.1130*radius_mean-33.6480*compactness_mean+14.3918*concavity_mean+19.0997*concave_points_mean+0.0944*area_se-30.3992*compactness_se -31.2549*concavity_se +34.8557 *concave_points_se +0.0112*radius_worst+0.0049*area_worst+4.9213*compactness_worst+7.6360*concavity_worst + 26.8649*concave_points_worst+74.5208*compactness_mean*concave_points_mean)
df2$compactness_mean_level = "medium"

df_combined<-rbind(df,df2)

## HIGH VALUE OF compactness_mean
df3 <- data.frame()
cancer_test_low = cancer_test%>%select(-compactness_mean,-concave_points_mean)
duprow=cancer_test_low[1,]
for(i in 1:150)
{
    df3 = rbind(df3,duprow)
}
concave_points_mean = seq(0,0.2,length.out=150)
df3$compactness_mean=0.28670
df3 <- cbind(df3,concave_points_mean)
df3<- df3%>%mutate(logit = -10.4871-0.1130*radius_mean-33.6480*compactness_mean+14.3918*concavity_mean+19.0997*concave_points_mean+0.0944*area_se-30.3992*compactness_se -31.2549*concavity_se +34.8557 *concave_points_se +0.0112*radius_worst+0.0049*area_worst+4.9213*compactness_worst+7.6360*concavity_worst + 26.8649*concave_points_worst+74.5208*compactness_mean*concave_points_mean)
df3$compactness_mean_level = "high"

df_combined<-rbind(df_combined,df3)

## FUNCTION TO GET THE Probability

get_probability<-function(log_odds){
  odds=exp(log_odds)
  odds/(1+odds)
}

## get probability
df_combined<-df_combined%>%
  rowwise()%>%
  mutate(probability = get_probability(logit))

ggplot(df_combined, aes(x=concave_points_mean, y=probability, color=compactness_mean_level, shape=compactness_mean_level)) +labs(title = "Interaction between concave points mean and compactness mean", x = "Concave Points Mean")+
  geom_point() + 
  geom_smooth(method = "glm", 
    method.args = list(family = "binomial"), 
    se = FALSE) 
```

### Prediction

Using the logistic regression model, besides classification we also want to understand uncertainty - more specifically, predictive probabilities that a tumor is benign or malignant given the values of the predictors:

```{r}
# Make predictions on the test data
x.test <- model.matrix(diagnosis~.-diagnosis_binary-texture_mean-smoothness_mean-symmetry_mean-fractal_dimension_mean-texture_se-smoothness_se-symmetry_se-fractal_dimension_se-texture_worst-smoothness_worst-symmetry_worst-symmetry_worst-fractal_dimension_worst+compactness_mean*concave_points_mean, cancer_test)[,-1]
probabilities <- lasso.model %>% predict(newx = x.test, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "M", "B")

#Present the prediction
predictors<-cancer_test%>%select(concave_points_mean,area_se,compactness_se,radius_worst,concavity_worst,concave_points_worst,compactness_mean,compactness_se,concavity_se,concavity_mean,radius_mean,concave_points_se,area_worst,compactness_worst)
predicted_results<-cbind(predictors,probabilities)%>%
  rename(probabilities=s0)
predicted_results<-cbind(predicted_results,predicted.classes)%>%
  rename("predicted_class"=s0)
predicted_results%>%head(12)%>%kable(digits=3)
# Model accuracy
observed.classes <- cancer_test$diagnosis
mean(predicted.classes == observed.classes)
```

We achieved a prediction accuracy of 0.9883. To interpret the predictions, we see that a patient with tumor with `concave_points_mean` of 0.147, `area_se` of 153.400, `compactness_se` of 0.049040, `radius_worst` of 25.380, `concavity_worst` of 0.711900, `concave_points_worst` of 0.26540, `compactness_mean` of 0.27760, `concavity_se` of 0.053730, `concavity_mean` of 0.300100, `radius_mean` of 17.990, `concave_points_se` of 0.712, `area_worst` of 2019.0, `compactness_worst` of 0.66560 is expected to have a 100% of being diagnosed as malignant tumor. On the other hand, a patient with tumor with `concave_points_mean` of 0.031100, `area_se` of 14.670, `compactness_se` of 0.018980, `radius_worst` of 14.500, `concavity_worst` of 0.189000, `concave_points_worst` of 0.07283, `compactness_mean` of 0.12700, `concavity_se` of 0.016980, `concavity_mean` of 0.018980, `radius_mean` of 13.080, `concave_points_se` of 0.006490, `area_worst` of 630.5, `compactness_worst` of 0.27760 is expected to have a 87.47e% of being diagnosed as malignant tumor.A patient with tumor with `concave_points_mean` of 0.055980, `area_se` of 24.910, `compactness_se` of 0.029950, `radius_worst` of 15.890, `concavity_worst` of 0.518600, `concave_points_worst` of 0.14470, `compactness_mean` of 0.10980, `concavity_se` of 0.048150, `concavity_mean` of 0.131900, `radius_mean` of 14.250, `concave_points_se` of 0.011610, `area_worst` of 799.6, `compactness_worst` of 0.42380 is expected to have a 87.47% of being diagnosed as malignant tumor. 


## Model 2: Support Vector Machine

We fitted a linear kernel SVM and a radial kernel SVM to compare the performance between the two kernels and select the one that provides the better formance on test data.

### Linear Kernel SVM

We use the predictors selected by the LASSO penalized logistic regression as predictors for the support vector machine model in order to avoid overfitting.

We tune the hyperparameter cost through cross validation considering a range of values from 0.001 to 100, and selected the optimal cost = 0.1 

```{r}
set.seed(876)
tune.out <- tune(svm, diagnosis_binary ~concave_points_mean+area_se+compactness_se+radius_worst+concavity_worst+concave_points_worst+compactness_mean+compactness_se+concavity_se+concavity_mean+radius_mean+concave_points_se+area_worst+compactness_worst+compactness_mean*concave_points_mean, data = cancer_train, kernel = "linear",
                 ranges = list(cost = c(0.001, 0.01, 0.1,
                                        1, 5, 10, 100)))
summary(tune.out)
best_linear_svm <- tune.out$best.model
summary(best_linear_svm)
```

Then we predicted on our test set and obtained the following truth table:

```{r, echo=F}
devtools::install_github("yihui/printr")
require(printr)
ypred <- predict(best_linear_svm, cancer_test)
table(predict = ypred, truth = cancer_test$diagnosis_binary)
classification_error <- 1- sum(ypred == cancer_test$diagnosis_binary)/length(ypred)
classification_error
```

As previously explained, we associate level 1  with malignant tumors and level -1 with benign tumors. According to the truth table, there are 3 test samples with true category malignant predicted as benign, whereas there are 2 test samples with true category benign predicted as malignant. The misclassification rate is 0.02924.

### Radial Kernel SVM

We tune the hyperparameter cost and gamma through cross validation considering a range of values of cost from 0.001 to 1000, gamma from 0.5 to 4, and selected the optimal cost = 1, gamma = 0.5

```{r}
set.seed(5)
tune.out <- tune(svm, diagnosis_binary ~ concave_points_mean+area_se+compactness_se+radius_worst+concavity_worst+concave_points_worst+compactness_mean+compactness_se+concavity_se+concavity_mean+radius_mean+concave_points_se+area_worst+compactness_worst+compactness_mean*concave_points_mean, data = cancer_train,
                 kernel = "radial",
                 ranges = list(cost = c(0.1, 1, 10, 100, 1000),
                               gamma = c(0.5, 1, 2, 3, 4)))
summary(tune.out)
best_radial_svm <- tune.out$best.model
summary(best_radial_svm)
```

Then we predicted on our test set and obtained the following truth table:

```{r}
ypred <- predict(best_radial_svm, cancer_test)
table(predict = ypred, truth = cancer_test$diagnosis_binary)
classification_error <- 1- sum(ypred == cancer_test$diagnosis_binary)/length(ypred)
classification_error
```

According to the truth table, there are 3 test samples with true category malignant predicted as benign, whereas there are 2 test samples with true category benign predicted as malignant. The misclassification rate is 0.02924 which is equal to that of the linear kernel. This suggests that the two classes are likely to be linearly separable so that we can find a separating hyperplane using the linear kernel, therefore the linear kernel SVM suffices for our particular dataset. 


### SVM Visualization

We visualize the decision boundaries of the linear and radial SVM kernels plotting pairs of predictors, taking `concavity_mean` and `texture_se` as examples:

### Linear

```{r, echo=F, warning=F, fig.height = 3, fig.width = 4}
tune.out <- tune(svm, diagnosis_binary ~ concavity_mean+radius_se+texture_se+smoothness_se, data = cancer_train, kernel = "linear",
                 ranges = list(cost = c(0.001, 0.01, 0.1,
                                        1, 5, 10, 100)))
best_linear_graph <- tune.out$best.model

plot(best_linear_graph, cancer_train, radius_se~concavity_mean)
```

```{r, echo=F, warning=F, fig.height = 3, fig.width = 4}
plot(best_linear_graph, cancer_train, texture_se~concavity_mean)
```

### Radial

```{r, echo=F, warning=F, fig.height = 3, fig.width = 4}
tune.out <- tune(svm, diagnosis_binary ~ concavity_mean+radius_se+texture_se+smoothness_se,
                 kernel = "radial", data = cancer_train,
                 ranges = list(cost = c(0.1, 1, 10, 100, 1000),
                               gamma = c(0.5, 1, 2, 3, 4)))
best_radial_graph <- tune.out$best.model

plot(best_radial_graph, cancer_train, texture_se~concavity_mean)
```

```{r, echo=F, warning=F, fig.height = 3, fig.width = 4}
plot(best_radial_graph, cancer_train, concavity_mean~texture_se)
```


### ROC

We visualize the ROC curves of linear and radial kernel SVMs on test and train data respectively.

On train data: 

```{r, echo=F, warning=F, fig.height = 4, fig.width = 5}
library(pROC)
fitted <- attributes(predict(best_linear_svm, cancer_train,
                             decision.values=TRUE))$decision.values
ROC_svm1 <- roc(cancer_train$diagnosis_binary, fitted)

fitted <- attributes(predict(best_radial_svm, cancer_train,
                             decision.values=TRUE))$decision.values
ROC_svm2 <- roc(cancer_train$diagnosis_binary, fitted)
plot(ROC_svm1, col = "blue")
lines(ROC_svm2, col = "red")
legend("bottomright", legend = c("Linear", "Radial"), 
       col = c("blue", "red"), lty = 1)
```

On test data: 

```{r, echo=F, warning=F, fig.height = 4, fig.width = 5}
fitted <- attributes(predict(best_linear_svm, cancer_test,
                             decision.values=TRUE))$decision.values
ROC_svm1 <- roc(cancer_test$diagnosis_binary, fitted)

fitted <- attributes(predict(best_radial_svm, cancer_test,
                             decision.values=TRUE))$decision.values
ROC_svm2 <- roc(cancer_test$diagnosis_binary, fitted)
plot(ROC_svm1, col = "blue")
lines(ROC_svm2, col = "red")
legend("bottomright", legend = c("Linear", "Radial"), 
       col = c("blue", "red"), lty = 1)
```

Even though the radial kernel fits the training data more closely due to its higher complexity, the linear kernel performs better on the test data (since the data is likely to be linearly separable as explained above), we decided to select the model with the linear kernel, which will result in lower variance and similarly low bias according to the ROC curves above.

## Model 3: Random Forest

Now, we are going to build a Random Forest model to compare with Lasso and SVM. We chose Random Forest because it uses bootstrap sampling and feature sampling, so it is not affected by multicollinearity that much since it is picking different set of features for different models and of course every model sees a different set of data points. What's more, it is easy and straightforward to interpret a tree model, so it can help us understanding the importance of the variables than LASSO.

First, We select variables by running a preliminary random forest model with all the variables, to rank their importance. 

```{r}
rf <- randomForest(diagnosis_binary~.-diagnosis, data=cancer_train, proximity=TRUE)
importance(rf)
```

After testing different variables based on their important, and taking into accounts the collinearity issue we discussed in the EDA section, we decided to select the following variables as the predictors:
concave_points_worst, area_worst, perimeter_worst, radius_worst, concave_points_mean, perimeter_mean, concavity_worst, area_se.

We chose mtry=2, because after tuning mtry, we found that mtry=2 has the lowest OOB error.

```{r}
set.seed(123)
rf_predictors <- cancer_train %>% select(concave_points_worst, area_worst, perimeter_worst, radius_worst, concave_points_mean, perimeter_mean, concavity_worst, area_se)
mtry <- tuneRF(rf_predictors, cancer_train$diagnosis_binary, ntreeTry=500,
               stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE, doBest = TRUE)
```

We chose the number of tree to be 500. The number of trees should be chosen carefully, since a high performance of the individual models might lead to overfitting when the number of trees is very high. However, taking 50 trees caused a lower accuracy than taking 500 trees. Therefore, this higher number
of trees is chosen. 

```{r}
set.seed(123)
rf_mix <- randomForest(diagnosis_binary~concave_points_worst+area_worst+perimeter_worst+radius_worst+concave_points_mean+perimeter_mean+concavity_worst+area_se, data = cancer_train, proximity=TRUE, mtry=2)
print(rf_mix)
```
```{r}
pred_mix <- predict(rf_mix, cancer_test)
confusionMatrix(pred_mix, cancer_test$diagnosis_binary)
```
The RF model yields a 96% accuracy for the testing set. 

```{r, echo=F, warning=F, fig.height = 4, fig.width = 5}
ImpDatamix <- as.data.frame(importance(rf_mix))
ImpDatamix$Var.Names <- row.names(ImpDatamix)

ggplot(ImpDatamix, aes(x=Var.Names, y= MeanDecreaseGini)) +
  geom_segment(aes(x=Var.Names, xend=Var.Names, y=0, yend=MeanDecreaseGini), color="skyblue") +
  theme_light() +
  coord_flip() +
  theme(
    legend.position="bottom",
    panel.grid.major.y = element_blank(),
    panel.border = element_blank(),
    axis.ticks.y = element_blank()
  )
```

From the plot we can see that the most important predictors are: concave_points_worst, concave_points_mean, area_worst, perimeter_worst, and radius_worst. Interestingly, perimeter_worst has high gini coefficient, but perimeter_mean ranks second from the last.

# Conclusion & Future Work

The result of the LASSO model shows that radius, compactness, concavity, and concave points are the most important variables. The result of the RF model suggest that radius, perimeter, area, and concave points are the most important variables. We can conclude that nuclear perimeter and compactness was highly significant in differentiating hyperplasia from carcinoma.

Both of the models highlights concave points as the most crucial variable. Concavity is the severity of concave portions of the contour. A high concavity means that the boundary of the cell nucleus has indentations, and thus is rather rough than smooth. Concave points counted the number of concave portions of the contour of the cell nucleus. If the contour contains one real cell, the added concave point separates one cell into two parts. Therefore, the higher number the concave points, the more irregular the shape is. 

When the tumor is benign, the cells shows mild variation in size and shape. 
Both of the models highlights concave points as the most crucial variable. Concavity is the severity of concave portions of the contour. A high concavity means that the boundary of the cell nucleus has indentations, and thus is rather rough than smooth. If the contour contains one real cell, the added concave point separates one cell into two parts. Therefore, the higher number the concave points, the more irregular the shape is. 

The following two pictures shows the cytological features for benigh Fibroadenoma and Fibrocystic disease. When the tumor is benign, the cells shows mild variation in size and shape. 

![benign1](pics/IJABMR-3-22-g001.jpeg){width=20%, height=20%}
![benign2](pics/IJABMR-3-22-g002.jpeg){width=20%, height=20%}
However, when the cancer is malignant carcinoma, we can observe loosely arranged clusters of ductal epithelial cells showing nuclear pleomorphism, increased nuclear cytoplasmic ratio, nuclear indentations, and hyperchromatic nucleus.

![malignant](pics/IJABMR-3-22-g004.jpeg){width=20%, height=20%}

Our results is correspondent with the clinical evidence. The ductal carcinoma cells showed higher values for nuclear area, perimeter, diameter, compactness, and concave points when compared to fibroadenomas, fibrocystic disease, and hyperplasia. In the present study, the size related parameters (area, perimeter, diameter, concave points and compactness) of the nucleus were appropriate parameters to differentiate between benign lesions and infiltrative ductal carcinoma of the breast. These parameters showed significant differences between the benign breast lesions and carcinoma.

When applying these 3 models to the test set, the LASSO-Penalized Logistic model yields an accuracy of 98.8%; both linear and Radial SVM model yields an accuracy around 97%, and the Random Forest model has an accuracy of 96%. LASSO has the highest accuracy in prediction. On the other hand, RF models use fewer predictors, but it gives a more intuitive result. Since breast cancer is a vital disease, false negative is much more dangerous than false positive. The false negative rate in the linear SVM is:, in a radial SVM is:, and in the RF is: . 

One limitation of our study is that although there are 30 variables, there are only 3 categories (mean, se, worst), and many of them are highly correlated. In future works, it would be interesting to see if other exogenous variables such as the patients' age, sex, and health conditions have potential effects in the accuracy of breast cancer diagnosis. 

# Citations

Narasimha A, Vasavi B, Kumar HM. Significance of nuclear morphometry in benign and malignant breast aspirates. Int J Appl Basic Med Res. 2013 Jan;3(1):22-6. doi: 10.4103/2229-516X.112237. PMID: 23776836; PMCID: PMC3678677.

Wolberg WH, Street WN, Mangasarian OL. Importance of nuclear morphology in breast cancer prognosis. Clin Cancer Res. 1999;5:3542â€“8.

# Appendix

| Variable Name            | Description                                                                                                                               |
|------------------|------------------------------------------------------|
| diagnosis       | The diagnosis of breast tissues (M = malignant, B = benign)
                               |
| radius_mean | mean of distances from center to points on the perimeter
 |
| texture_mean | standard deviation of gray-scale values                                        |
| perimeter_mean  | mean size of the core tumor
                                     |
| area_mean         | placeholder                                    |
| smoothness_mean         | mean of local variation in radius lengths
                                  |
| compactness_mean          | mean of perimeter^2 / area - 1.0
                                                                                    |
| concavity_mean        | mean of severity of concave portions of the contour
                                                                                  |
| concave points_mean          | mean for number of concave portions of the contour
                                                                                   |
| symmetry_mean          | placeholder
                                                                                   |
| fractal_dimension_mean          | mean for "coastline approximation" - 1
                                                                                   |
